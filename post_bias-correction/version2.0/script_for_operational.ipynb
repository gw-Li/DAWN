{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88126b31-6571-4bcd-941e-15306da58801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library have loaded!\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "import datetime \n",
    "import warnings\n",
    "import subprocess\n",
    "import numpy        as np\n",
    "import pandas       as pd\n",
    "import xarray       as xr\n",
    "print('Library have loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "472092a9-5554-43ee-b90a-a83b3a035474",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Information of path and loop index\n",
    "path_obs_monthly  = '/scratch16/umd-xliang/CFS_seasonal_forecast/DATA/OBS/regrid_monthly/'\n",
    "path_cwrf_hindcast= '/scratch16/umd-xliang/shinsa11/Exp2023Dec_NonBC/CWRF-post/'\n",
    "path_climatology  = '/scratch16/umd-xliang/CFS_seasonal_forecast/DATA/cwrf_operational/climatology/'\n",
    "path_operational  = '/scratch16/umd-xliang/aditya/cwrf_operational/CWRF-post/V0/'\n",
    "path_adjustment   = '/scratch16/umd-xliang/CFS_seasonal_forecast/DATA/CWRF_v0_adjustment/'\n",
    "static_path       = '/scratch16/umd-xliang/CFS_seasonal_forecast/DATA/static/'\n",
    "MASK_US           = xr.open_dataset(f'{static_path}US_MASK_logic.nc')['MASK']\n",
    "path_v0_adj       = '/scratch16/umd-xliang/CFS_seasonal_forecast/DATA/CWRF_v0_adjustment/'\n",
    "path_climatology  = '/scratch16/umd-xliang/CFS_seasonal_forecast/DATA/cwrf_operational/climatology/'\n",
    "years             = range(2012,2023+1)\n",
    "months            = range(1,12+1)\n",
    "exps              = ['00','02']\n",
    "var_names         = ['T2MAX','T2MIN']\n",
    "vnames            = ['AQ2M','ASNOW','ASNOWH','AGHT_PL','AT2M','ATSK','AU_PL','AV_PL','AXTSS','AXWICE','AXWLIQ','PSFC','RH','uv_10','T2MAX','T2MIN','PRAVG']\n",
    "\n",
    "\n",
    "# Functions used for adjustment\n",
    "def mkdir_adj_folder(path_adj_folder):\n",
    "    folder_path = path_adj_folder\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"The folder was created at {folder_path}\")\n",
    "    else:\n",
    "        print(f\"The folder already exists at {folder_path}\")\n",
    "\n",
    "\n",
    "def check_mkdir_dawn(user_server,  raw_init_date):\n",
    "    path_dawn     = '/mnt/gfs01/PUB/S2S/V2023-07/Operational/'\n",
    "    dir_path = f'{path_dawn}{raw_init_date}/' \n",
    "    remote_check = f'ssh -p 2322 -o StrictHostKeyChecking=no {user_server} \"[ -d \\\"{dir_path}\\\" ] && echo Exists || echo NotExists\"'\n",
    "    \n",
    "    result = subprocess.run(remote_check, shell=True, capture_output=True, text=True)\n",
    "    \n",
    "    if \"NotExists\" in result.stdout:\n",
    "        command = f'ssh -p 2322 -o StrictHostKeyChecking=no {user_server} \"mkdir -p \\\"{dir_path}\\\" && chmod 777 \\\"{dir_path}\\\"\"'\n",
    "        exit_status = os.system(command)\n",
    "        if exit_status == 0:\n",
    "            print(\"Command executed successfully!\")\n",
    "        else:\n",
    "            print(f\"Command failed with exit status {exit_status}.\")\n",
    "    else:\n",
    "        print(\"Directory already exists!\")\n",
    "        return\n",
    "\n",
    "    \n",
    "def adjustment(raw_init_date,var_name,path_cwrf_raw,path_adj_folder):\n",
    "    year,month,day =int(raw_init_date[:4]), int(raw_init_date[4:6]),int(raw_init_date[6:8])\n",
    "    for exp in exps:\n",
    "        # Read the climatology of observation\n",
    "        obs_cli = xr.open_dataset(f'{path_climatology}OBS/OBS_climatology_{var_name}_{years[0]}-{years[-1]}.nc')\n",
    "        # Read the climatology of CWRF\n",
    "        cwrf_cli = xr.open_dataset(f'{path_climatology}CWRF/CWRF_exp{exp}_climatology_{var_name}_{years[0]}-{years[-1]}_{month:02}{day:02}.nc')\n",
    "        # Read the CWRF data\n",
    "        cwrf_ds = xr.open_dataset(f'{path_cwrf_raw}{year}{month:02}{day:02}_icbc01_exp{exp}_{var_name}_daily.nc')\n",
    "\n",
    "        # Create an empty dataset to store the adjusted data\n",
    "        adjusted_ds = cwrf_ds.copy(deep=True)\n",
    "        adjusted_ds[var_name].values[:] = np.nan  # Initialize with NaNs\n",
    "\n",
    "        # Loop through each month in the CWRF dataset to apply adjustment\n",
    "        for m in np.unique(cwrf_ds['time'].dt.month.values[:-1]):\n",
    "            # Find the adjustment for the month\n",
    "            Adjustment = obs_cli[var_name].sel(month=m) - cwrf_cli[var_name].sel(month=m)\n",
    "            # Apply the adjustment for the specific month\n",
    "            mask = cwrf_ds['time'].dt.month == m\n",
    "            adjusted_ds[var_name].loc[{'time': mask}] = cwrf_ds[var_name].loc[{'time': mask}] + Adjustment\n",
    "        # Drop the 'month' coordinate if it's no longer needed\n",
    "        adjusted_ds = adjusted_ds.drop_vars('month', errors='ignore')\n",
    "        adjusted_ds = xr.where(MASK_US, adjusted_ds, cwrf_ds)\n",
    "        adjusted_ds = adjusted_ds.transpose('time', 'bottom_top', 'south_north', 'west_east')\n",
    "        adjusted_ds[var_name].loc[{'time':cwrf_ds['time'][-1] }] = cwrf_ds[var_name].loc[{'time': cwrf_ds['time'][-1] }]\n",
    "        # Preserving global attributes\n",
    "        adjusted_ds.attrs = cwrf_ds.attrs\n",
    "        # Preserving variable attributes for all variables including coordinates\n",
    "        for var in adjusted_ds.variables:\n",
    "            adjusted_ds[var].attrs = cwrf_ds[var].attrs\n",
    "        adjusted_ds.to_netcdf(f'{path_adj_folder}{year}{month:02}{day:02}_icbc01_exp{exp}_{var_name}_daily.nc')\n",
    "\n",
    "def calculate_the_ensemble_mean(vname,path_cwrf_raw, raw_init_date, path_adj):\n",
    "    # Pattern for file matching\n",
    "    pattern = f'{raw_init_date}_icbc01_exp*_{vname}_daily.nc'\n",
    "    # Collect files matching the pattern\n",
    "    files = []\n",
    "    for dirpath, dirnames, filenames in os.walk(path_cwrf_raw):\n",
    "        for filename in filenames:\n",
    "            if filename.startswith(pattern.split('*')[0]) and filename.endswith(pattern.split('*')[1]):\n",
    "                files.append(os.path.join(dirpath, filename))\n",
    "    # Load datasets and store attributes\n",
    "    datasets = []\n",
    "    global_attributes = None\n",
    "    variable_attributes = {}\n",
    "    ensemble_specific_attributes = {}  # For attributes that vary across files\n",
    "    for file in files:\n",
    "        ds = xr.open_dataset(file, chunks={'south_north': 23})\n",
    "        if global_attributes is None:\n",
    "            global_attributes = ds.attrs\n",
    "            for var in ds.variables:\n",
    "                if var not in ds.coords:\n",
    "                    variable_attributes[var] = ds[var].attrs\n",
    "        # Store varying attributes as a list\n",
    "        for attr in ['CU_PHYSICS', 'RA_LW_PHYSICS', 'RA_SW_PHYSICS', 'BL_PBL_PHYSICS']:  # Add other attributes as needed\n",
    "            if attr in ds.attrs:\n",
    "                if attr not in ensemble_specific_attributes:\n",
    "                    ensemble_specific_attributes[attr] = []\n",
    "                ensemble_specific_attributes[attr].append(ds.attrs[attr])\n",
    "        datasets.append(ds)\n",
    "    # Concatenate datasets into an ensemble\n",
    "    ensemble_data = xr.concat(datasets, dim='ensemble')\n",
    "    # Calculate the ensemble mean\n",
    "    ensemble_mean = ensemble_data.mean(dim='ensemble')\n",
    "    # Apply global and variable attributes\n",
    "    ensemble_mean.attrs = global_attributes\n",
    "    for var in ensemble_mean.variables:\n",
    "        if var in variable_attributes:\n",
    "            ensemble_mean[var].attrs = variable_attributes[var]\n",
    "    # Modify global attributes for ensemble-specific values\n",
    "    for attr, values in ensemble_specific_attributes.items():\n",
    "        ensemble_mean.attrs[attr] = ', '.join(map(str, values))\n",
    "    # Modify specific attributes to reflect the ensemble nature\n",
    "    filenames_only = [os.path.basename(file) for file in files]\n",
    "    ensemble_history_str = \"The script for ensemble was written by Guangwei Li. Ensemble mean computed from multiple files: \" + ', '.join(filenames_only)\n",
    "    ensemble_mean.attrs['ensemble_history'] = ensemble_history_str\n",
    "    # Save the ensemble mean dataset with the preserved attributes\n",
    "    if vname not in ['T2MAX', 'T2MIN']:\n",
    "        outfile = os.path.join(path_adj, f'{raw_init_date}_icbc01_ensemble_mean_{vname}_daily.nc')\n",
    "    else:\n",
    "        if path_cwrf_raw == path_adj:\n",
    "            outfile = os.path.join(path_adj, f'{raw_init_date}_icbc01_ensemble_mean_{vname}_daily.nc')\n",
    "        else:\n",
    "            outfile = os.path.join(path_adj, f'{raw_init_date}_icbc01_ensemble_mean_{vname}_daily_no_adj.nc')            \n",
    "    ensemble_mean.to_netcdf(outfile)\n",
    "    print(f'{outfile} has been calculated!')\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "288ba245-27a2-4df3-857d-9f51c2596801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='scp -P 2322 /scratch16/umd-xliang/CFS_seasonal_forecast/DATA/CWRF_v0_adjustment/20240220/*   guangwei@129.2.80.228:/mnt/gfs01/PUB/S2S/V2023-07/Operational/20240220/', returncode=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Adjust the 2024 CWRF simulations\n",
    "\n",
    "\n",
    "# pbc.post_bias_correction(raw_init_date,var_name,user_server,path_cwrf_raw)\n",
    "raw_init_date     = '20240220'\n",
    "user_server       = 'guangwei@129.2.80.228'\n",
    "path_cwrf_raw     = '/scratch16/umd-xliang/aditya/cwrf_operational/CWRF-post/V0/'\n",
    "\n",
    "def post_bias_correction(raw_init_date,user_server,path_cwrf_raw):\n",
    "    # create a folder to adjusted file and ensemble file. simulation file is also coped\n",
    "    path_adj_folder = f'{path_v0_adj}{raw_init_date}/'\n",
    "    mkdir_adj_folder(path_adj_folder)\n",
    "\n",
    "    # Copy file, so that to transfer to DAWN by one scp command line.\n",
    "    command = f'cp  {path_cwrf_raw}{raw_init_date}*  {path_adj_folder}'\n",
    "    subprocess.run(command, shell=True)\n",
    "\n",
    "    # Bias-correction （Executed after copy to avoid being overwritten by the source file）\n",
    "    for var_name in var_names:\n",
    "        adjustment(raw_init_date,var_name,path_cwrf_raw,path_adj_folder)\n",
    "\n",
    "    # Ensemble mean\n",
    "    for var_name in vnames:\n",
    "        try:\n",
    "            calculate_the_ensemble_mean(var_name,path_cwrf_raw, raw_init_date, path_adj_folder)\n",
    "        except:\n",
    "            print(f'{var_name} raw file not exists.')\n",
    "    for var_name in var_names:\n",
    "        calculate_the_ensemble_mean(var_name,path_adj_folder, raw_init_date, path_adj_folder)\n",
    "\n",
    "\n",
    "    # Transfer to DAWN server\n",
    "    check_mkdir_dawn(user_server,raw_init_date)\n",
    "    command =f'scp -P 2322 {path_adj_folder}*   {user_server}:/mnt/gfs01/PUB/S2S/V2023-07/Operational/{raw_init_date}/'\n",
    "    subprocess.run(command, shell=True)\n",
    "\n",
    "    subprocess.run(f'rm -rf {path_adj_folder}', shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff70eb5-a088-469a-86b2-42a7acbe969b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc42d96-daed-4092-9123-c5beecca44d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14281d26-c97d-48a6-ad7c-5d81a71c63c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (post_bias_correction.py, line 223)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/work/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3505\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[40], line 7\u001b[0;36m\n\u001b[0;31m    import post_bias_correction   as     pbc\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/bias_correction/my_functions/post_bias_correction.py:223\u001b[0;36m\u001b[0m\n\u001b[0;31m    os.system(f'scp -P 2322 {path_pbc}{f'{raw_init_date}_icbc01_exp*_{var_name}_*.nc'}  {user_server}:{path_dawn}{raw_init_date}/')\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "raw_init_date = '20240225'\n",
    "# user_server   = 'shinsa11@129.2.80.228'\n",
    "path_cwrf_raw = '/scratch16/umd-xliang/aditya/cwrf_operational/CWRF-post/V0/'\n",
    "user_server   = 'guangwei@129.2.80.228'\n",
    "\n",
    "import os\n",
    "import post_bias_correction   as     pbc\n",
    "\n",
    "pbc.post_bias_correction(raw_init_date,user_server,path_cwrf_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba8c5f4-8aab-4861-8888-5b4ead6a8848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90d02e-1464-4f17-a4fb-29ea6e1f0de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd27551f-7dee-4d3c-b127-964e067a4686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758af845-d7ca-47f2-86fb-26207df4bb45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9408ccea-7e6f-4f91-bfed-0858b344f8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a1bd6-49d3-4d31-b438-eb34c1c1693e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf09068-7064-4efc-bc74-56218f971db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67c894-b6fe-418d-98e6-e86bb7c0411b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a9538-6772-4922-b8d7-479d8bf217fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed2166-7bcf-46b9-8879-d8ef186b6574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaae8ff-c1fa-4380-8f06-5cdb8c9f04f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8e57af-b1af-47f6-96f7-bab5fcc47c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16234bf3-c549-4fae-b88d-0bcabf76b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab275d10-2ef7-4163-9aeb-eb180a129468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
